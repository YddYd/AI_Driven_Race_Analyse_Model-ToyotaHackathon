{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dSqOYX3CRq7"
   },
   "outputs": [],
   "source": [
    "# 1. Clean environment\n",
    "!pip uninstall -y torch torchvision torchaudio torchtext torchdata\n",
    "\n",
    "# 2.  mamba-ssm cp312 wheel  torch 2.4.0\n",
    "!pip install torch==2.4.0+cu118 torchvision==0.19.0+cu118 torchaudio==2.4.0+cu118 \\\n",
    "  --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ixu1eRCSEBeh"
   },
   "outputs": [],
   "source": [
    "# 3.  cp312 wheel（Avoid compilation; install prebuilt wheel）\n",
    "!pip install \\\n",
    "  https://github.com/state-spaces/mamba/releases/download/v2.2.6.post3/mamba_ssm-2.2.6.post3+cu11torch2.4cxx11abiFALSE-cp312-cp312-linux_x86_64.whl\n",
    "\n",
    "import torch, mamba_ssm\n",
    "print(torch.__version__)\n",
    "print(mamba_ssm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDy2umH582QB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "CSV_PATH = \"PATH/processed_data.csv\"  #  Colab \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df[\"ts\"] = pd.to_datetime(df[\"ts\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "print(\"ts dtype:\", df[\"ts\"].dtype)\n",
    "print(df.head(3))\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df.head(3))\n",
    "\n",
    "#  vehicle_id \n",
    "df[\"car_no\"] = df[\"vehicle_id\"].str[-3:].astype(int)\n",
    "\n",
    "#  Race 1 Sonoma \n",
    "top_cars = [46, 13, 55, 2, 16, 78, 98, 88, 71, 31]\n",
    "df_top = df[df[\"car_no\"].isin(top_cars)].copy()\n",
    "\n",
    "#  flying （90–120s ，，）\n",
    "#  all_merged_with_dist_progress  flying-only + strict\n",
    "#  is_true_flying/in_90_120 ，：\n",
    "# df_top = df_top[df_top[\"is_true_flying\"] == True]\n",
    "\n",
    "# \n",
    "lap_times = (\n",
    "    df_top\n",
    "    .groupby([\"vehicle_id\", \"car_no\", \"lap\"])[\"ts\"]\n",
    "    .agg(lambda x: (x.iloc[-1] - x.iloc[0]).total_seconds())\n",
    "    .reset_index(name=\"lap_time_real\")\n",
    ")\n",
    "\n",
    "# Pick the fastest lap for each vehicle 3 \n",
    "best3 = (\n",
    "    lap_times\n",
    "    .sort_values([\"vehicle_id\", \"lap_time_real\"])\n",
    "    .groupby(\"vehicle_id\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(\"3：\")\n",
    "print(best3)\n",
    "\n",
    "#  is_best_lap \n",
    "keys = best3[[\"vehicle_id\", \"lap\"]].copy()\n",
    "keys[\"is_best_lap\"] = True\n",
    "\n",
    "df_best = df_top.merge(keys, on=[\"vehicle_id\", \"lap\"], how=\"inner\")\n",
    "df_best = df_best.sort_values([\"vehicle_id\", \"lap\", \"ts\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"：\")\n",
    "print(df_best.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Va6lg6nO9wmu"
   },
   "outputs": [],
   "source": [
    "# Select a reference car: 46 (GR86-033-046)\n",
    "ref_vid = best3[best3[\"car_no\"] == 46][\"vehicle_id\"].iloc[0]\n",
    "ref_lap = best3[best3[\"vehicle_id\"] == ref_vid].sort_values(\"lap_time_real\")[\"lap\"].iloc[0]\n",
    "\n",
    "print(\":\", ref_vid, \"lap\", ref_lap)\n",
    "\n",
    "ref = df_best[(df_best[\"vehicle_id\"] == ref_vid) & (df_best[\"lap\"] == ref_lap)].copy()\n",
    "ref = ref.sort_values(\"ts\").reset_index(drop=True)\n",
    "\n",
    "# G\n",
    "ref[\"steer_smooth\"] = ref[\"Steering_Angle\"].rolling(7, center=True, min_periods=1).mean()\n",
    "ref[\"accy_smooth\"] = ref[\"accy_can\"].rolling(7, center=True, min_periods=1).mean()\n",
    "\n",
    "#  corner : 5  0.2 \n",
    "steer_thresh = 5.0\n",
    "accy_thresh = 0.2\n",
    "\n",
    "corner_mask = (ref[\"steer_smooth\"].abs() > steer_thresh) | (ref[\"accy_smooth\"].abs() > accy_thresh)\n",
    "\n",
    "corners = []\n",
    "start = None\n",
    "\n",
    "for i, flag in enumerate(corner_mask):\n",
    "    if flag and start is None:\n",
    "        start = i\n",
    "    # ：，\n",
    "    if (not flag or i == len(corner_mask) - 1) and start is not None:\n",
    "        end = i\n",
    "        dt = (ref.loc[end, \"ts\"] - ref.loc[start, \"ts\"]).total_seconds()\n",
    "        if dt >= 0.4:  # \n",
    "            corners.append((start, end, dt))\n",
    "        start = None\n",
    "\n",
    "print(\" corner :\", len(corners))\n",
    "\n",
    "corner_rows = []\n",
    "for idx, (s, e, dt) in enumerate(corners, start=1):\n",
    "    seg = ref.loc[s:e]\n",
    "    corner_rows.append({\n",
    "        \"corner_index\": idx,\n",
    "        \"idx_start\": s,\n",
    "        \"idx_end\": e,\n",
    "        \"dt_corner\": dt,\n",
    "        \"progress_start\": seg[\"progress_dist\"].iloc[0],\n",
    "        \"progress_end\": seg[\"progress_dist\"].iloc[-1],\n",
    "        \"steer_mean\": seg[\"steer_smooth\"].mean(),\n",
    "        \"steer_sign\": \"right\" if seg[\"steer_smooth\"].mean() > 0 else \"left\",\n",
    "        \"speed_min\": seg[\"speed\"].min(),\n",
    "        \"speed_max\": seg[\"speed\"].max(),\n",
    "    })\n",
    "\n",
    "corner_map = pd.DataFrame(corner_rows)\n",
    "print(\" progress_dist ：\")\n",
    "print(corner_map[[\"corner_index\",\"progress_start\",\"progress_end\",\"steer_sign\",\"dt_corner\",\"speed_min\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YOBy3Ds_30w"
   },
   "outputs": [],
   "source": [
    "# Assign corner_index for all best laps corner_index\n",
    "def assign_corner_index(row, corner_map):\n",
    "    p = row[\"progress_dist\"]\n",
    "    #  progress_start <= p <= progress_end \n",
    "    matches = corner_map[(p >= corner_map[\"progress_start\"]) & (p <= corner_map[\"progress_end\"])]\n",
    "    if len(matches) == 0:\n",
    "        return 0  # Not inside any corner，\n",
    "    # ， progress_start \n",
    "    return int(matches.sort_values(\"progress_start\").iloc[-1][\"corner_index\"])\n",
    "\n",
    "df_best[\"corner_index\"] = df_best.apply(assign_corner_index, axis=1, corner_map=corner_map)\n",
    "\n",
    "print(df_best[[\"vehicle_id\",\"lap\",\"ts\",\"progress_dist\",\"Steering_Angle\",\"corner_index\"]].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBPgS4YwquWl"
   },
   "outputs": [],
   "source": [
    "# ：\n",
    "# df       = processed_data.csv 、 progress_dist、ts \n",
    "# df[\"car_no\"] = ...\n",
    "# df_top   = df[df[\"car_no\"].isin(top_cars)].copy()\n",
    "# corner_map （progress_start / progress_end ）\n",
    "\n",
    "# 1)  df_top  corner_index（ best laps ）\n",
    "def assign_corner(row, corner_map):\n",
    "    p = row[\"progress_dist\"]\n",
    "    matches = corner_map[\n",
    "        (p >= corner_map[\"progress_start\"]) &\n",
    "        (p <= corner_map[\"progress_end\"])\n",
    "    ]\n",
    "    if len(matches) == 0:\n",
    "        return 0  # \n",
    "    return int(matches.sort_values(\"progress_start\").iloc[-1][\"corner_index\"])\n",
    "\n",
    "df_top = df_top.sort_values([\"vehicle_id\",\"lap\",\"ts\"]).reset_index(drop=True)\n",
    "df_top[\"corner_index\"] = df_top.apply(assign_corner, axis=1, corner_map=corner_map)\n",
    "\n",
    "# 2)  Steering （ window=5）\n",
    "df_top[\"Steering_smooth\"] = (\n",
    "    df_top\n",
    "    .groupby([\"vehicle_id\",\"lap\"])[\"Steering_Angle\"]\n",
    "    .transform(lambda s: s.rolling(window=5, center=True, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# \n",
    "df_top[\"ath_smooth\"] = (\n",
    "    df_top\n",
    "    .groupby([\"vehicle_id\", \"lap\"])[\"ath\"]\n",
    "    .transform(lambda s: s.rolling(window=5, center=True, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# \n",
    "df_top[\"pbrake_f_smooth\"] = (\n",
    "    df_top\n",
    "    .groupby([\"vehicle_id\", \"lap\"])[\"pbrake_f\"]\n",
    "    .transform(lambda s: s.rolling(window=5, center=True, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "\n",
    "print(df_top[[\n",
    "    \"vehicle_id\",\"lap\",\"ts\",\n",
    "    \"Steering_Angle\",\"Steering_smooth\",\n",
    "    \"ath\",\"ath_smooth\",\n",
    "    \"pbrake_f\",\"pbrake_f_smooth\"\n",
    "    ]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0wjT6DKOF3b"
   },
   "outputs": [],
   "source": [
    "# ====== STEP3:  Steering （label smoothing） ======\n",
    "# ：\n",
    "# - 、 rolling，Avoid contamination across laps\n",
    "# - window=5 （，）\n",
    "\n",
    "df_best = df_best.sort_values([\"vehicle_id\", \"lap\", \"ts\"]).reset_index(drop=True)\n",
    "\n",
    "df_best[\"Steering_smooth\"] = (\n",
    "    df_best\n",
    "    .groupby([\"vehicle_id\", \"lap\"])[\"Steering_Angle\"]\n",
    "    .transform(lambda s: s.rolling(window=5, center=True, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# \n",
    "df_best[\"ath_smooth\"] = (\n",
    "    df_best\n",
    "    .groupby([\"vehicle_id\", \"lap\"])[\"ath\"]\n",
    "    .transform(lambda s: s.rolling(window=5, center=True, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# \n",
    "df_best[\"pbrake_f_smooth\"] = (\n",
    "    df_best\n",
    "    .groupby([\"vehicle_id\", \"lap\"])[\"pbrake_f\"]\n",
    "    .transform(lambda s: s.rolling(window=5, center=True, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "print(df_best[[\n",
    "    \"vehicle_id\",\"lap\",\"ts\",\n",
    "    \"Steering_Angle\",\"Steering_smooth\",\n",
    "    \"ath\",\"ath_smooth\",\n",
    "    \"pbrake_f\",\"pbrake_f_smooth\"\n",
    "]].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B68VJTY9_4qZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_best = df_best.sort_values([\"vehicle_id\", \"lap\", \"ts\"]).reset_index(drop=True)\n",
    "\n",
    "# ： progress_dist  progress， corner_index\n",
    "OBS_FEATURES = [\n",
    "    \"progress_dist\",       # \n",
    "    \"corner_index\",        # （0 = ，1,2,... = ）\n",
    "    \"speed\",\n",
    "    \"accx_can\",\n",
    "    \"accy_can\",\n",
    "    \"nmot\",\n",
    "    \"gear\",\n",
    "]\n",
    "\n",
    "# \n",
    "ACT_FEATURES = [\"Steering_smooth\", \"ath_smooth\", \"pbrake_f_smooth\"]\n",
    "\n",
    "\n",
    "\n",
    "print(\":\", OBS_FEATURES)\n",
    "print(\":\", ACT_FEATURES)\n",
    "\n",
    "sequences: List[Dict] = []\n",
    "\n",
    "for (vid, lap), g in df_best.groupby([\"vehicle_id\", \"lap\"]):\n",
    "    g = g.reset_index(drop=True)\n",
    "    obs = g[OBS_FEATURES].values.astype(np.float32)\n",
    "    act = g[ACT_FEATURES].values.astype(np.float32)\n",
    "    if len(g) < 5:\n",
    "        continue\n",
    "    sequences.append({\n",
    "        \"vehicle_id\": vid,\n",
    "        \"lap\": int(lap),\n",
    "        \"obs\": obs,\n",
    "        \"act\": act,\n",
    "    })\n",
    "\n",
    "print(\":\", len(sequences))\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "indices = list(range(len(sequences)))\n",
    "random.shuffle(indices)\n",
    "split = int(len(indices) * 0.8)\n",
    "train_idx = indices[:split]\n",
    "val_idx = indices[split:]\n",
    "\n",
    "train_seqs = [sequences[i] for i in train_idx]\n",
    "val_seqs   = [sequences[i] for i in val_idx]\n",
    "\n",
    "print(f\": {len(train_seqs)}, : {len(val_seqs)}\")\n",
    "\n",
    "\n",
    "obs_train_concat = np.concatenate([s[\"obs\"] for s in train_seqs], axis=0)\n",
    "act_train_concat = np.concatenate([s[\"act\"] for s in train_seqs], axis=0)\n",
    "\n",
    "obs_mean = obs_train_concat.mean(axis=0, keepdims=True)\n",
    "obs_std  = obs_train_concat.std(axis=0, keepdims=True) + 1e-6\n",
    "\n",
    "act_mean = act_train_concat.mean(axis=0, keepdims=True)\n",
    "act_std  = act_train_concat.std(axis=0, keepdims=True) + 1e-6\n",
    "\n",
    "def normalize_obs(x: np.ndarray) -> np.ndarray:\n",
    "    return (x - obs_mean) / obs_std\n",
    "\n",
    "def normalize_act(y: np.ndarray) -> np.ndarray:\n",
    "    return (y - act_mean) / act_std\n",
    "\n",
    "for s in train_seqs:\n",
    "    s[\"obs_norm\"] = normalize_obs(s[\"obs\"])\n",
    "    s[\"act_norm\"] = normalize_act(s[\"act\"])\n",
    "\n",
    "for s in val_seqs:\n",
    "    s[\"obs_norm\"] = normalize_obs(s[\"obs\"])\n",
    "    s[\"act_norm\"] = normalize_act(s[\"act\"])\n",
    "\n",
    "# ============== Dataset & DataLoader（） ==============\n",
    "\n",
    "class DrivingSequenceDataset(Dataset):\n",
    "    def __init__(self, seqs):\n",
    "        self.seqs = seqs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.seqs[idx]\n",
    "        obs = s[\"obs_norm\"]\n",
    "        act = s[\"act_norm\"]\n",
    "        length = obs.shape[0]\n",
    "        return {\n",
    "            \"obs\": torch.from_numpy(obs),\n",
    "            \"act\": torch.from_numpy(act),\n",
    "            \"length\": length,\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_len = max(item[\"length\"] for item in batch)\n",
    "    batch_size = len(batch)\n",
    "    D_obs = batch[0][\"obs\"].shape[1]\n",
    "    D_act = batch[0][\"act\"].shape[1]\n",
    "\n",
    "    obs_batch = torch.zeros(batch_size, max_len, D_obs, dtype=torch.float32)\n",
    "    act_batch = torch.zeros(batch_size, max_len, D_act, dtype=torch.float32)\n",
    "    mask = torch.zeros(batch_size, max_len, dtype=torch.bool)\n",
    "\n",
    "    for i, item in enumerate(batch):\n",
    "        L = item[\"length\"]\n",
    "        obs_batch[i, :L] = item[\"obs\"]\n",
    "        act_batch[i, :L] = item[\"act\"]\n",
    "        mask[i, :L] = True\n",
    "\n",
    "    return {\n",
    "        \"obs\": obs_batch.to(device),\n",
    "        \"act\": act_batch.to(device),\n",
    "        \"mask\": mask.to(device),\n",
    "        \"lengths\": torch.tensor([item[\"length\"] for item in batch], dtype=torch.long).to(device),\n",
    "    }\n",
    "\n",
    "train_dataset = DrivingSequenceDataset(train_seqs)\n",
    "val_dataset   = DrivingSequenceDataset(val_seqs)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6w6P5f7q95-"
   },
   "outputs": [],
   "source": [
    "# best3 best3 already contains the top 3 fastest laps of each car： vehicle_id, car_no, lap, lap_time_real\n",
    "\n",
    "# 1)  best laps \n",
    "best_keys = set((row[\"vehicle_id\"], int(row[\"lap\"])) for _, row in best3.iterrows())\n",
    "\n",
    "# 2)  df_top “ best3” = \n",
    "slow_candidates = []\n",
    "for (vid, lap), g in df_top.groupby([\"vehicle_id\",\"lap\"]):\n",
    "    key = (vid, int(lap))\n",
    "    if key in best_keys:\n",
    "        continue  # \n",
    "    if len(g) < 5:\n",
    "        continue  # \n",
    "    slow_candidates.append((vid, int(lap), g[\"ts\"].iloc[0]))\n",
    "\n",
    "print(\":\", len(slow_candidates))\n",
    "print(\":\", slow_candidates[:10])\n",
    "\n",
    "# OBS_FEATURES  ACT_FEATURES ：\n",
    "OBS_FEATURES = [\n",
    "    \"progress_dist\",\n",
    "    \"corner_index\",\n",
    "    \"speed\",\n",
    "    \"accx_can\",\n",
    "    \"accy_can\",\n",
    "    \"nmot\",\n",
    "    \"gear\",\n",
    "]\n",
    "\n",
    "ACT_FEATURES = [\"Steering_smooth\", \"ath_smooth\", \"pbrake_f_smooth\"]\n",
    "# ACT_FEATURES = [\"Steering_Angle\", \"ath\", \"pbrake_f\"]\n",
    "slow_seqs = []\n",
    "\n",
    "for (vid, lap, _) in slow_candidates:\n",
    "    g = df_top[(df_top[\"vehicle_id\"] == vid) & (df_top[\"lap\"] == lap)].copy()\n",
    "    g = g.sort_values(\"ts\").reset_index(drop=True)\n",
    "    obs = g[OBS_FEATURES].values.astype(np.float32)\n",
    "    act = g[ACT_FEATURES].values.astype(np.float32)\n",
    "    if len(g) < 5:\n",
    "        continue\n",
    "\n",
    "    obs_norm = (obs - obs_mean) / obs_std\n",
    "    act_norm = (act - act_mean) / act_std\n",
    "\n",
    "    slow_seqs.append({\n",
    "        \"vehicle_id\": vid,\n",
    "        \"lap\": int(lap),\n",
    "        \"obs\": obs,\n",
    "        \"act\": act,\n",
    "        \"obs_norm\": obs_norm,\n",
    "        \"act_norm\": act_norm,\n",
    "        \"corner_index\": g[\"corner_index\"].values.astype(np.int32),\n",
    "        \"progress_dist\": g[\"progress_dist\"].values.astype(np.float32),  # \n",
    "        # ，\n",
    "        \"ath\": g[\"ath\"].values.astype(np.float32),\n",
    "        \"pbrake_f\": g[\"pbrake_f\"].values.astype(np.float32),\n",
    "    })\n",
    "\n",
    "\n",
    "print(\" slow_seqs :\", len(slow_seqs))\n",
    "if slow_seqs:\n",
    "    print(\":\", slow_seqs[0][\"vehicle_id\"], \"lap\", slow_seqs[0][\"lap\"], \"len\", slow_seqs[0][\"obs\"].shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlKgbAWdaM7J"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# 6. Model Structure\n",
    "# ============================\n",
    "\n",
    "input_dim = len(OBS_FEATURES)\n",
    "output_dim = len(ACT_FEATURES)\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "\n",
    "from mamba_ssm import Mamba\n",
    "\n",
    "class DrivingMamba(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, d_state=16, d_conv=4, expand=2):\n",
    "        super().__init__()\n",
    "        self.mamba = Mamba(\n",
    "            d_model=hidden_dim,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand,\n",
    "        )\n",
    "        self.in_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        self.out_proj = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, obs, lengths=None):\n",
    "        # obs: (B, T, D_in)\n",
    "        x = self.in_proj(obs)        # (B, T, hidden_dim)\n",
    "        # Mamba  (B, T, hidden_dim)\n",
    "        y = self.mamba(x)            # (B, T, hidden_dim)\n",
    "        out = self.out_proj(y)       # (B, T, D_out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = DrivingMamba(input_dim, hidden_dim, output_dim).to(device)\n",
    "criterion = nn.MSELoss(reduction=\"none\")  #  mask \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNWmlaRzHu_4"
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Tools\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "def masked_mse_loss(pred, target, mask):\n",
    "    diff2 = (pred - target) ** 2  # (B, T, D)\n",
    "    diff2 = diff2.mean(dim=-1)    # (B, T)\n",
    "    diff2 = diff2 * mask.float()\n",
    "    loss = diff2.sum() / mask.float().sum().clamp(min=1.0)\n",
    "    return loss\n",
    "\n",
    "def run_one_epoch(dataloader, training=True):\n",
    "\n",
    "    model.train() if training else model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        obs = batch[\"obs\"].to(device)     # <-- \n",
    "        act = batch[\"act\"].to(device)     # <-- \n",
    "        mask = batch[\"mask\"].to(device)   # <-- \n",
    "        lengths = batch[\"lengths\"].to(device)  # \n",
    "\n",
    "        if training:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        pred = model(obs, lengths)  # (B, T, D_act)\n",
    "\n",
    "        loss = masked_mse_loss(pred, act, mask)\n",
    "\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        #  mask.float()  .cpu()  python float\n",
    "        count = mask.float().sum().item()\n",
    "\n",
    "        total_loss += loss.item() * count\n",
    "        total_count += count\n",
    "\n",
    "    if total_count == 0:\n",
    "        return float(\"inf\")\n",
    "\n",
    "    return total_loss / total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5wt2bEAID9Q"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 240 \n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss = run_one_epoch(train_loader, training=True)\n",
    "    val_loss = run_one_epoch(val_loader, training=False)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_loss = {train_loss:.6f} | val_loss = {val_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5szh2DGpQhDc"
   },
   "outputs": [],
   "source": [
    "def analyze_one_lap_diff(seq, model, act_mean, act_std, title=\"\"):\n",
    "    \"\"\"\n",
    "    seq: slow_seqs \n",
    "         : obs_norm, act_norm, corner_index, vehicle_id, lap\n",
    "         act_norm: (T, 3)   [Steering_smooth, ath_smooth, pbrake_f_smooth]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    obs_np = seq[\"obs_norm\"]           # (T, D_obs)\n",
    "    true_act_norm = seq[\"act_norm\"]    # (T, 3)\n",
    "    corner_idx = seq[\"corner_index\"]   # (T,)\n",
    "\n",
    "    obs = torch.from_numpy(obs_np).unsqueeze(0).to(device)\n",
    "    lengths = torch.tensor([obs_np.shape[0]], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_norm = model(obs, lengths)    # (1, T, 3)\n",
    "\n",
    "    pred_norm_np = pred_norm.squeeze(0).cpu().numpy()   # (T, 3)\n",
    "    true_norm_np = true_act_norm                         # (T, 3)\n",
    "\n",
    "    # \n",
    "    true_phys = true_norm_np * act_std + act_mean        # (T, 3)\n",
    "    pred_phys = pred_norm_np * act_std + act_mean        # (T, 3)\n",
    "\n",
    "    steer_true = true_phys[:, 0]\n",
    "    ath_true   = true_phys[:, 1]\n",
    "    brk_true   = true_phys[:, 2]\n",
    "\n",
    "    steer_pred = pred_phys[:, 0]\n",
    "    ath_pred   = pred_phys[:, 1]\n",
    "    brk_pred   = pred_phys[:, 2]\n",
    "\n",
    "    # Difference of the three actions\n",
    "    diff_steer = steer_pred - steer_true\n",
    "    diff_ath   = ath_pred   - ath_true\n",
    "    diff_brk   = brk_pred   - brk_true\n",
    "\n",
    "    T = steer_true.shape[0]\n",
    "    x = np.arange(T)\n",
    "\n",
    "    vid = seq.get(\"vehicle_id\", \"N/A\")\n",
    "    lap = seq.get(\"lap\", -1)\n",
    "\n",
    "    # =================  =================\n",
    "    plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # 1) Steering  vs \n",
    "    plt.subplot(6,1,1)\n",
    "    plt.plot(x, steer_true, label=\"True Steering\", linewidth=1.2)\n",
    "    plt.plot(x, steer_pred, label=\"Pred Steering\", linestyle=\"--\", linewidth=1.2)\n",
    "    plt.ylabel(\"Steer (deg)\")\n",
    "    plt.title(f\"{title}  {vid} lap {lap}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 2) Steering diff\n",
    "    plt.subplot(6,1,2)\n",
    "    plt.plot(x, diff_steer, label=\"Δ Steering (pred-true)\", linewidth=1.2)\n",
    "    plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    plt.ylabel(\"Δ Steer\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 3) Throttle  vs \n",
    "    plt.subplot(6,1,3)\n",
    "    plt.plot(x, ath_true, label=\"True Throttle\", linewidth=1.2)\n",
    "    plt.plot(x, ath_pred, label=\"Pred Throttle\", linestyle=\"--\", linewidth=1.0)\n",
    "    plt.ylabel(\"Throttle\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 4) Throttle diff\n",
    "    plt.subplot(6,1,4)\n",
    "    plt.plot(x, diff_ath, label=\"Δ Throttle (pred-true)\", linewidth=1.2)\n",
    "    plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    plt.ylabel(\"Δ Throttle\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 5) Brake  vs \n",
    "    plt.subplot(6,1,5)\n",
    "    plt.plot(x, brk_true, label=\"True Brake_f\", linewidth=1.2)\n",
    "    plt.plot(x, brk_pred, label=\"Pred Brake_f\", linestyle=\"--\", linewidth=1.0)\n",
    "    plt.ylabel(\"Brake_f\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 6) Brake diff\n",
    "    plt.subplot(6,1,6)\n",
    "    plt.plot(x, diff_brk, label=\"Δ Brake_f (pred-true)\", linewidth=1.2)\n",
    "    plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "    plt.ylabel(\"Δ Brake_f\")\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # =================  diff =================\n",
    "    result = []\n",
    "    corner_idx = np.array(corner_idx)\n",
    "\n",
    "    print(\"\\n===== Per-Corner （pred - true）=====\")\n",
    "    for c in sorted(set(corner_idx)):\n",
    "        if c == 0:\n",
    "            continue\n",
    "        mask = (corner_idx == c)\n",
    "        if mask.sum() < 3:\n",
    "            continue\n",
    "\n",
    "        s_mean = diff_steer[mask].mean()\n",
    "        t_mean = diff_ath[mask].mean()\n",
    "        b_mean = diff_brk[mask].mean()\n",
    "\n",
    "        print(\n",
    "            f\"corner {c:2d}: \"\n",
    "            f\"steer_diff={s_mean: .2f} deg, \"\n",
    "            f\"throttle_diff={t_mean: .2f}, \"\n",
    "            f\"brake_diff={b_mean: .2f}\"\n",
    "        )\n",
    "\n",
    "        result.append({\n",
    "            \"corner\": int(c),\n",
    "            \"steer_diff_mean\": float(s_mean),\n",
    "            \"throttle_diff_mean\": float(t_mean),\n",
    "            \"brake_diff_mean\": float(b_mean),\n",
    "        })\n",
    "\n",
    "    #  list， DataFrame\n",
    "    return result\n",
    "\n",
    "if slow_seqs:\n",
    "    seq0 = slow_seqs[1]  # \n",
    "    corner_table = analyze_one_lap_diff(\n",
    "        seq0, model, act_mean, act_std,\n",
    "        title=\"Slow lap analysis\"\n",
    "    )\n",
    "\n",
    "    #  per-corner diff \n",
    "    corner_df = pd.DataFrame(corner_table)\n",
    "    display(corner_df)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
